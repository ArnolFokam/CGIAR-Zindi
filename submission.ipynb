{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import sys \n",
    "sys.path.append('.')\n",
    "\n",
    "\n",
    "from cgiar.utils import get_dir\n",
    "from cgiar.model import XCITMultipleMLP\n",
    "from cgiar.data import CGIARDataset_V4, augmentations\n",
    "\n",
    "# reduce font size of plots\n",
    "plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "LR=1e-4\n",
    "EPOCHS=30\n",
    "IMAGE_SIZE=224\n",
    "INITIAL_SIZE=512\n",
    "TRAIN_BATCH_SIZE=128\n",
    "TEST_BATCH_SIZE=64\n",
    "HIDDEN_SIZE=512\n",
    "NUM_FOLDS=5\n",
    "NUM_VIEWS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = get_dir('data/')\n",
    "ARTIFACTS = get_dir('solutions/v10/#1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "    augmentations[\"RandomEqualize\"],\n",
    "    augmentations[\"RandomAffine\"],\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data frame from csv\n",
    "X_test = pd.read_csv(DATA_DIR / 'Test.csv')\n",
    "\n",
    "test_images = CGIARDataset_V4.load_images(X_test, DATA_DIR / \"test\", INITIAL_SIZE)\n",
    "test_images = dict([test_images[idx] for idx in range(len(test_images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct test dataset and dataloader\n",
    "test_dataset = CGIARDataset_V4(\n",
    "    images=test_images,\n",
    "    num_views=NUM_VIEWS,\n",
    "    transform=transform,\n",
    "    features=X_test,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_idx=3\n",
    "\n",
    "model = XCITMultipleMLP(\n",
    "    model_name=\"xcit_nano_12_p16_224\",\n",
    "    pretrained=True,\n",
    "    num_mlps=4,\n",
    "    hidden_size=HIDDEN_SIZE\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(ARTIFACTS / f\"model_fold_{fold_idx}.pth\"))\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for ids, images_list, growth_stage, season, _ in tqdm(test_loader):\n",
    "    \n",
    "        # average predictions from all the views\n",
    "        outputs = torch.stack([model((\n",
    "            growth_stage.to(device).squeeze(),\n",
    "            season.to(device).squeeze(),\n",
    "            images.to(device)\n",
    "        )) for images in images_list]).mean(dim=0)\n",
    "        \n",
    "        # get predictions from all the folds\n",
    "        outputs = outputs.tolist()\n",
    "        test_predictions.extend(list(zip(ids, outputs)))\n",
    "        \n",
    "# load the sample submission file and update the extent column with the predictions\n",
    "submission_df = pd.read_csv('data/SampleSubmission.csv')\n",
    "\n",
    "# update the extent column with the predictions\n",
    "submission_df['extent'] = submission_df['ID'].map(dict(test_predictions))\n",
    "\n",
    "# save the submission file and trained model\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 18/136 [01:02<06:50,  3.48s/it]"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    # 2: 0.3,\n",
    "    3: 0.1\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "for i in weights.keys():\n",
    "    # initialize the model\n",
    "    model = XCITMultipleMLP(\n",
    "        model_name=\"xcit_nano_12_p16_224\",\n",
    "        pretrained=True,\n",
    "        num_mlps=4,\n",
    "        hidden_size=HIDDEN_SIZE\n",
    "    )\n",
    "    \n",
    "    # load the model weights\n",
    "    model.load_state_dict(torch.load(ARTIFACTS / f\"model_fold_{i}.pth\"))\n",
    "    \n",
    "    # move model to gpu\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    models[i] = model\n",
    "\n",
    "test_ensemble_predictions = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ids, images_list, growth_stage, season, _ in tqdm(test_loader):\n",
    "        \n",
    "        outputs = torch.zeros(len(ids)).to(device)\n",
    "        \n",
    "        for idx in weights.keys():\n",
    "        \n",
    "            # average predictions from all the views\n",
    "            outputs += weights[idx] * torch.stack([model((\n",
    "                growth_stage.to(device).squeeze(),\n",
    "                season.to(device).squeeze(),\n",
    "                images.to(device)\n",
    "            )) for images in images_list]).mean(dim=0)\n",
    "        \n",
    "        # get predictions from all the folds\n",
    "        outputs = outputs.tolist()\n",
    "        test_ensemble_predictions.extend(list(zip(ids, outputs)))\n",
    "\n",
    "# load the sample submission file and update the extent column with the predictions\n",
    "submission_df = pd.read_csv('data/SampleSubmission.csv')\n",
    "\n",
    "# update the extent column with the predictions\n",
    "submission_df['extent'] = submission_df['ID'].map(dict(test_ensemble_predictions))\n",
    "\n",
    "# save the submission file and trained model\n",
    "submission_df.to_csv('submission_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgiar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
